{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6712fdc3cc4c259657c01889facff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>21</td><td>application_1589937331213_0022</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-27-153.ec2.internal:20888/proxy/application_1589937331213_0022/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-18-196.ec2.internal:8042/node/containerlogs/container_1589937331213_0022_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "spark_conf = SparkConf()\\\n",
    "        .setAppName(\"Cloud Computing Assignment\")\n",
    "\n",
    "sc=SparkContext.getOrCreate(spark_conf) \n",
    "\n",
    "ssc = StreamingContext(sc, 3)\n",
    "\n",
    "#You can change the input path pointing to your own HDFS\n",
    "#If spark is able to read hadoop configuration, you can use relative path\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Cloud Computing Assignment\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "test_matched = 's3://comp5349-auda0496/assignment/test_matched.tsv'\n",
    "test_mismatched = 's3://comp5349-auda0496/assignment/test_mismatched.tsv'\n",
    "dev_matched = 's3://comp5349-auda0496/assignment/dev_matched.tsv'\n",
    "dev_mismatched = 's3://comp5349-auda0496/assignment/dev_mismatched.tsv'\n",
    "stop_words_file = 's3://comp5349-auda0496/assignment/stop_words.txt'\n",
    "stop_words = sc.textFile(stop_words_file).map(lambda word: str(word)).collect()\n",
    "trainFile = 's3://comp5349-auda0496/assignment/train.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebc34fc9b6441c4b74d0d83d21e9b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def extractSentence(record):    \n",
    "    row = record.split('\\t')\n",
    "\n",
    "    if len(row) < 10 : \n",
    "        return []    \n",
    "    else: #normal record\n",
    "        firstSentence = row[8]\n",
    "        secondSentence = row[9]    \n",
    "        return [firstSentence]+[secondSentence]\n",
    "\n",
    "def extractWord(record):\n",
    "    words = word_tokenize(record)\n",
    "    extractedWords = [(word.lower(),1) for word in words if word.isalpha()]\n",
    "    return extractedWords\n",
    "\n",
    "def tagRow(row, tag):    \n",
    "    return (row[0], tag)\n",
    "\n",
    "def getWordsTagged(devFile, testFile, matchType):\n",
    "    devData = sc.textFile(devFile)\n",
    "    devHeader = devData.first() #get headers from first row\n",
    "    devData = devData.filter(lambda row : row != devHeader) #get data from other rows\n",
    "\n",
    "    testData = sc.textFile(testFile)\n",
    "    testHeader = testData.first() #get headers from first row\n",
    "    testData = testData.filter(lambda row : row != testHeader) #get data from other rows\n",
    "\n",
    "    data = devData.union(testData)\n",
    "\n",
    "    sentence = data.flatMap(extractSentence)\n",
    "    words = sentence.flatMap(extractWord).distinct() #get unique mismatched words\n",
    "    wordsTagged = words.map(lambda row: tagRow(row,matchType))\n",
    "    return wordsTagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adb4d988ecd4cb0a26e51dab09df86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common words: 9079\n",
      "Number of unique matched words: 8970\n",
      "Number of unique mismatched words: 6414"
     ]
    }
   ],
   "source": [
    "mismatchedWordsTagged = getWordsTagged(dev_mismatched,test_mismatched, \"mis\")\n",
    "matchedWordsTagged = getWordsTagged(dev_matched,test_matched, \"mat\")\n",
    "wordsTagged = matchedWordsTagged.fullOuterJoin(mismatchedWordsTagged)\n",
    "commonWords = wordsTagged.filter(lambda x: x[1][0]!=None and x[1][1]!=None)\n",
    "mismatchedUniqueWords = wordsTagged.filter(lambda x: x[1][0]==None and x[1][1]!=None)\n",
    "matchedUniqueWords = wordsTagged.filter(lambda x: x[1][0]!=None and x[1][1]==None)\n",
    "\n",
    "print(\"Number of common words: \" +str(commonWords.count())) \n",
    "print(\"Number of unique matched words: \" +str(matchedUniqueWords.count())) \n",
    "print(\"Number of unique mismatched words: \" +str(mismatchedUniqueWords.count())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad436a46b4c4774b1808b88a3baf6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extractSentenceWithGenre(record):    \n",
    "    row = record.split('\\t')\n",
    "    if len(row) < 10 :\n",
    "        return []\n",
    "    genre = row[3]\n",
    "    firstSentence = row[8]\n",
    "    secondSentence = row[9]\n",
    "    return [(genre,firstSentence)]+[(genre,secondSentence)]\n",
    "    \n",
    "def extractWordWithGenre(sentenceGenrePair, isStopwordsRemoved):    \n",
    "    genre = sentenceGenrePair[0]\n",
    "    sentence = sentenceGenrePair[1]\n",
    "    wordsRawData = word_tokenize(sentence)\n",
    "    words = [word.lower() for word in wordsRawData if word.isalpha()] \n",
    "    if isStopwordsRemoved:\n",
    "        words = [word for word in words if not word in stop_words] \n",
    "    return [(word, genre) for word in words]\n",
    "\n",
    "def mergeGenreWords(accumulatedPair, currentGenreWord):\n",
    "    ratingTotal, ratingCount = accumulatedPair\n",
    "    ratingTotal += currentGenreWord\n",
    "    ratingCount = ratingCount + 1\n",
    "    return (ratingTotal, ratingCount)\n",
    "\n",
    "def mergeCombiners(accumulatedPair1, accumulatedPair2):\n",
    "    ratingTotal1, ratingCount1 = accumulatedPair1\n",
    "    ratingTotal2, ratingCount2 = accumulatedPair2\n",
    "    return (ratingTotal1+ratingTotal2, ratingCount1+ratingCount2)\n",
    "\n",
    "def mapWordGenreCount(wordGenrePair):\n",
    "    return (wordGenrePair[0], wordGenrePair[1][1])\n",
    "\n",
    "def wordGenrePercentageCount(isStopwordsRemoved, trainSentence):\n",
    "    trainWords = trainSentence.flatMap(lambda x: extractWordWithGenre(x, isStopwordsRemoved)).distinct()\n",
    "    wordsCount = trainWords.aggregateByKey(([],0), mergeGenreWords, mergeCombiners, 1).map(mapWordGenreCount)\n",
    "    count = []\n",
    "    \n",
    "    for genre in range(1,6):\n",
    "        count.append(wordsCount.filter(lambda x: x[1] == genre).count())\n",
    "    print(\"without stopwords in:\" if isStopwordsRemoved else \"with stopwords in:\")\n",
    "    totalWordCount = 0\n",
    "    genreCount = 0\n",
    "    for i in count:\n",
    "        totalWordCount = totalWordCount + i\n",
    "    for i in count:\n",
    "        genreCount = genreCount + 1\n",
    "        print(str(genreCount) + \" genre : \" +str(i/totalWordCount*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab93c186bdf3435c8c891d9d52b89354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words appearing\n",
      "without stopwords in:\n",
      "1 genre : 56.29497220244497\n",
      "2 genre : 15.351521669974098\n",
      "3 genre : 9.50873312832321\n",
      "4 genre : 7.654552891097207\n",
      "5 genre : 11.190220108160513\n",
      "with stopwords in:\n",
      "1 genre : 56.1781109717205\n",
      "2 genre : 15.32171520986684\n",
      "3 genre : 9.493508260153263\n",
      "4 genre : 7.649521621499071\n",
      "5 genre : 11.357143936760327"
     ]
    }
   ],
   "source": [
    "trainData = sc.textFile(trainFile)\n",
    "trainHeader = trainData.first() #extract header\n",
    "trainData = trainData.filter(lambda row : row != trainHeader)   #filter out header\n",
    "trainSentence = trainData.flatMap(extractSentenceWithGenre)\n",
    "\n",
    "print(\"Percentage of words appearing\")\n",
    "wordGenrePercentageCount(True, trainSentence) #Stopwords Removed\n",
    "wordGenrePercentageCount(False, trainSentence) #Stopwords Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863b8cc0aa534b47bde8bf7db294bf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (id, rdd) in sc._jsc.getPersistentRDDs().items(): rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b0396587b3477ea27a190bd45b2ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel #https://spark.apache.org/docs/2.2.0/mllib-clustering.html\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "\n",
    "def review_embed(rev_text_partition):\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "    embed = hub.Module(module_url)\n",
    "    # mapPartition would supply element inside a partition using generator stype\n",
    "    # this does not fit tensorflow stype\n",
    "    rev_text_list = [text for text in rev_text_partition]\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed(rev_text_list))\n",
    "    return message_embeddings\n",
    "\n",
    "def sequencer(accumulatedPair, currentItem):\n",
    "    return accumulatedlist + [currentItem]\n",
    "\n",
    "def combiner(accumulatedPair1, accumulatedPair2):\n",
    "    return accumulatedPair1 + accumulatedPair2\n",
    "\n",
    "def recurringCheck(x, clusterMapped):\n",
    "    for i in clusterMapped:\n",
    "        if x == i[1]:\n",
    "            return i[0]\n",
    "        \n",
    "def kMeanCluster(embeddedWords, trainSentence):\n",
    "    clusters = KMeans.train(embeddedWords, 5, maxIterations= 1)\n",
    "\n",
    "    prediction = clusters.predict(embeddedWords)\n",
    "    result = prediction.zip(trainSentence).map(lambda x:(x[0],x[1][0]))\n",
    "\n",
    "    sum = (lambda x, y : x + y)\n",
    "\n",
    "    aCount = result.map(lambda x : (x, 1)).aggregateByKey(0, sum, sum, 1)\n",
    "\n",
    "    accuracy = sorted(aCount.collect(), key=lambda x: - x[1])\n",
    "\n",
    "    clusterName = []\n",
    "    genre = []\n",
    "\n",
    "    for i in accuracy:\n",
    "        if i[0][0] in clusterName or i[0][1] in genre:\n",
    "            continue\n",
    "        clusterName = clusterName + [i[0][0]]\n",
    "        genre = genre + [i[0][1]]\n",
    "\n",
    "    clusterZip = zip(cluster_name, genre_name)\n",
    "    clusterMapped = set(clusterZip)\n",
    "    \n",
    "    aCount.aggregateByKey\n",
    "    \n",
    "    KMeanPredictions = aCount.map(lambda x: (x[0][0], (recurringCheck(x[0][1],clusterMapped), x[1])))\n",
    "    result = KMeanPredictions.aggregateByKey([], sequencer, combiner, 1).map(lambda x: (x[0], dict(x[1])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b51063d442a41b0aa51a68d87e14484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_file = 's3://comp5349-auda0496/assignment/train.tsv'\n",
    "\n",
    "trainData = sc.textFile(trainFile)\n",
    "trainHeader = trainData.first() #extract header\n",
    "trainData = trainData.filter(lambda row : row != trainHeader)   #filter out header\n",
    "trainSentence = trainData.flatMap(extractSentenceWithGenre)\n",
    "\n",
    "cleanText = trainSentence.map(lambda row: str(row[1])).filter(lambda data: data is not None).cache()\n",
    "reviewEmbedding = cleanText.mapPartitions(review_embed).cache()\n",
    "trainDataUSE = reviewEmbedding.map(lambda x: [float(a) for a in x.tolist()])\n",
    "\n",
    "trainData.unpersist()\n",
    "cleanText.unpersist()\n",
    "reviewEmbedding.unpersist()\n",
    "\n",
    "accuracyKmeansUSE = kMeanCluster(trainDataUSE, trainSentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6fb1c5ec7f42e583a3f9c3a0d4eeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[107] at RDD at PythonRDD.scala:53"
     ]
    }
   ],
   "source": [
    "trainDataUSE.unpersist()\n",
    "#Kmeans_USE_prediction.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e9192d8d0b4c37abf8378d1ac3eb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (id, rdd) in sc._jsc.getPersistentRDDs().items(): rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef32ffe4ec349589ed2e46aea512ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_file = 's3://comp5349-auda0496/assignment/train.tsv'\n",
    "\n",
    "trainData = sc.textFile(trainFile)\n",
    "trainHeader = trainData.first() #extract header\n",
    "trainData = trainData.filter(lambda row : row != trainHeader)   #filter out header\n",
    "trainSentence = trainData.flatMap(extractSentenceWithGenre)\n",
    "\n",
    "cleanText = trainSentence.map(lambda row: str(row[1])).filter(lambda data: data is not None).cache()\n",
    "\n",
    "hashingTF = HashingTF()\n",
    "tf = hashingTF.transform(cleanText)\n",
    "\n",
    "# While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:\n",
    "# First to compute the IDF vector and second to scale the term frequencies by IDF.\n",
    "tf.cache()\n",
    "idf = IDF().fit(tf)\n",
    "tfidf = idf.transform(tf)\n",
    "\n",
    "accuracyKmeansTFIDF = kMeanCluster(tfidf, trainSentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc3c7399cb54198a9c0eb8e2715dd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, {1: 134997, 3: 58651, 2: 12423, 4: 96431, 0: 10820}), (3, {1: 1122, 2: 47149, 0: 3122, 4: 9401, 3: 15626}), (0, {0: 126663, 3: 13756, 1: 11015, 2: 2599, 4: 8639}), (2, {0: 3567, 2: 78221, 3: 51152, 1: 3997, 4: 12449}), (4, {2: 14308, 1: 3565, 4: 39776, 0: 10528, 3: 15427})]"
     ]
    }
   ],
   "source": [
    "accuracyKmeansUSE.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9154d13247984c3581de56ffe80cdb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, {3: 90936, 4: 104378, None: 123934, 1: 135117, 0: 86914}), (2, {1: 9, 4: 12, 0: 163}), (0, {None: 42091, 1: 15568, 3: 45047, 0: 51843, 4: 39725}), (4, {None: 54, 4: 136, 3: 1670, 1: 3305, 0: 44}), (3, {4: 10361, 0: 15736, 1: 697, 3: 17047, None: 617})]"
     ]
    }
   ],
   "source": [
    "accuracyKmeansTFIDF.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fe685798b944e8bde943bc71db503b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeansDf = spark.createDataFrame(accuracyKmeansUSE).toDF(\"predicted_value\", \"count\")\n",
    "\n",
    "kmeansMatrix = kmeansDf.withColumn(\"0\", kmeansDf[\"count\"][0])\\\n",
    ".withColumn(\"1\", kmeansDf[\"count\"][1])\\\n",
    ".withColumn(\"2\", kmeansDf[\"count\"][2])\\\n",
    ".withColumn(\"3\", kmeansDf[\"count\"][3])\\\n",
    ".withColumn(\"4\", kmeansDf[\"count\"][4])\\\n",
    ".drop(\"count\").sort(\"predicted_value\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c42ec8712046368e9bf00b163281cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+------+-----+-----+-----+\n",
      "|predicted_value|     0|     1|    2|    3|    4|\n",
      "+---------------+------+------+-----+-----+-----+\n",
      "|              0|126663| 11015| 2599|13756| 8639|\n",
      "|              1| 10820|134997|12423|58651|96431|\n",
      "|              2|  3567|  3997|78221|51152|12449|\n",
      "|              3|  3122|  1122|47149|15626| 9401|\n",
      "|              4| 10528|  3565|14308|15427|39776|\n",
      "+---------------+------+------+-----+-----+-----+"
     ]
    }
   ],
   "source": [
    "kmeansMatrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2134da789ae14ce0b40bc3ba61e54e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|predicted_value|            0_norm|            1_norm|            2_norm|            3_norm|            4_norm|\n",
      "+---------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|              0| 77.86404544113307| 6.771294383790695|1.5976935182453034| 8.456280121963214|  5.31068653486771|\n",
      "|              1|3.4533163965505134| 43.08570735537243|3.9649306464276366| 18.71908132847358| 30.77696427317584|\n",
      "|              2| 2.387773954721326| 2.675618866560454| 52.36166709062429| 34.24149518696531|  8.33344490112862|\n",
      "|              3| 4.085317979586495|1.4682020413504318| 61.69719968594609|20.447526825438366|12.301753467678617|\n",
      "|              4|12.592698913927563| 4.264150040667911| 17.11401368355581| 18.45246638916798| 47.57667097268073|\n",
      "+---------------+------------------+------------------+------------------+------------------+------------------+"
     ]
    }
   ],
   "source": [
    "kmeansAddMatrix = kmeansMatrix\\\n",
    ".withColumn(\"total\", kmeansMatrix[\"0\"]+kmeansMatrix[\"1\"]+kmeansMatrix[\"2\"]+kmeansMatrix[\"3\"]+kmeansMatrix[\"4\"])\\\n",
    "\n",
    "kmeansAddMatrix\\\n",
    ".withColumn(\"0_norm\", (kmeansAddMatrix[\"0\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"1_norm\", (kmeansAddMatrix[\"1\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"2_norm\", (kmeansAddMatrix[\"2\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"3_norm\", (kmeansAddMatrix[\"3\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"4_norm\", (kmeansAddMatrix[\"4\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".drop(\"0\",\"1\",\"2\",\"3\",\"4\",\"total\").sort(\"predicted_value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846bcc9d1c67421eb63fa9b2709a283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+------+------+------+------+\n",
      "|predicted_value|     0|     1|     2|     3|     4|\n",
      "+---------------+------+------+------+------+------+\n",
      "|              0|138992|136785|104405|112086|111977|\n",
      "|              1|   987| 22654|   475|   837|   470|\n",
      "|              2|  5585|  3733| 16063| 13056| 14111|\n",
      "|              3|  6909|  3291| 13975| 13842|  6968|\n",
      "|              4|  2223|   233| 19782| 14791| 21174|\n",
      "+---------------+------+------+------+------+------+\n",
      "\n",
      "+---------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|predicted_value|            0_norm|             1_norm|            2_norm|            3_norm|            4_norm|\n",
      "+---------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|              0| 23.00259000901952|  22.63734081374277|17.278587327987818|18.549760444852666|18.531721404397224|\n",
      "|              1|3.8823112929237307|  89.10828777091609|1.8683868937576211|3.2922943791055346|1.8487196632970144|\n",
      "|              2|10.628377864048108|  7.103981122021771|30.568242368881783| 24.84585521808632|26.853543426962016|\n",
      "|              3|15.358452817605869|  7.315771923974658| 31.06591085917528| 30.77025675225075|15.489607646993441|\n",
      "|              4| 3.819390753053966|0.40032300740511656| 33.98793876604299| 25.41277940999605| 36.37956806350188|\n",
      "+---------------+------------------+-------------------+------------------+------------------+------------------+"
     ]
    }
   ],
   "source": [
    "kmeansDf = spark.createDataFrame(accuracyKmeansTFIDF).toDF(\"predicted_value\", \"count\")\n",
    "\n",
    "kmeansMatrix = kmeansDf.withColumn(\"0\", kmeansDf[\"label_count\"][0])\\\n",
    ".withColumn(\"1\", kmeansDf[\"count\"][1])\\\n",
    ".withColumn(\"2\", kmeansDf[\"count\"][2])\\\n",
    ".withColumn(\"3\", kmeansDf[\"count\"][3])\\\n",
    ".withColumn(\"4\", kmeansDf[\"count\"][4])\\\n",
    ".drop(\"count\").sort(\"predicted_value\")\n",
    "\n",
    "kmeansMatrix.show()\n",
    "\n",
    "kmeansAddMatrix = kmeansMatrix\\\n",
    ".withColumn(\"total\", kmeansMatrix[\"0\"]+kmeansMatrix[\"1\"]+kmeansMatrix[\"2\"]+kmeansMatrix[\"3\"]+kmeansMatrix[\"4\"])\\\n",
    "\n",
    "kmeansAddMatrix\\\n",
    ".withColumn(\"0_norm\", (kmeansAddMatrix[\"0\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"1_norm\", (kmeansAddMatrix[\"1\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"2_norm\", (kmeansAddMatrix[\"2\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"3_norm\", (kmeansAddMatrix[\"3\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".withColumn(\"4_norm\", (kmeansAddMatrix[\"4\"]*100/kmeansAddMatrix[\"total\"]))\\\n",
    ".drop(\"0\",\"1\",\"2\",\"3\",\"4\",\"total\").sort(\"predicted_value\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
